{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e12383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snowpylot import caaml_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e11ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pits(folder_path):\n",
    "    \"\"\"\n",
    "    Function to parse CAAML files in the specified folder with error handling\n",
    "    \"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    files = [\n",
    "        f for f in os.listdir(folder_path) if f.endswith(\".xml\")\n",
    "    ]  # List of all .xml files in the folder\n",
    "\n",
    "    pits_list = []\n",
    "    failed_files = []\n",
    "    \n",
    "    print(f\"Found {len(files)} XML files to process...\")\n",
    "\n",
    "    for i, file in enumerate(files):  # iterate through each file in the folder\n",
    "        try:\n",
    "            file_path = folder_path + \"/\" + file  # create the file path\n",
    "            \n",
    "            # First, do a quick XML validation check\n",
    "            ET.parse(file_path).getroot()\n",
    "            \n",
    "            # If XML is valid, parse with caaml_parser\n",
    "            pit = caaml_parser(file_path)  # parse the file\n",
    "            pits_list.append(pit)\n",
    "                \n",
    "        except ET.ParseError as e:\n",
    "            failed_files.append((file, f\"XML ParseError: {e}\"))\n",
    "            print(f\"⚠️ Skipping {file}: XML ParseError - {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_files.append((file, f\"Other error: {e}\"))\n",
    "            print(f\"⚠️ Skipping {file}: {type(e).__name__} - {e}\")\n",
    "    \n",
    "    print(f\"✅ Successfully parsed {len(pits_list)} files\")\n",
    "    print(f\"⚠️ Failed to parse {len(failed_files)} files\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(\"Failed files:\")\n",
    "        for file, error in failed_files[:10]:  # Show first 10 failed files\n",
    "            print(f\"  - {file}: {error}\")\n",
    "        if len(failed_files) > 10:\n",
    "            print(f\"  ... and {len(failed_files) - 10} more\")\n",
    "\n",
    "    return pits_list, failed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2f6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50278 XML files to process...\n",
      "✅ Successfully parsed 50278 files\n",
      "⚠️ Failed to parse 0 files\n",
      "\n",
      "Dataset summary:\n",
      "Total successfully parsed pits: 50278\n",
      "Total failed files: 0\n"
     ]
    }
   ],
   "source": [
    "# Parse all pits with error handling\n",
    "all_pits, failed_files = parse_pits(\"../snowpits/combined_caaml_files/\")\n",
    "\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Total successfully parsed pits: {len(all_pits)}\")\n",
    "print(f\"Total failed files: {len(failed_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137e3305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating summary statistics...\n",
      "Creating DataFrame...\n",
      "✅ Successfully created DataFrame with 50278 rows and 23 columns\n",
      "DataFrame shape: (50278, 23)\n"
     ]
    }
   ],
   "source": [
    "# Create summary statistics DataFrame efficiently\n",
    "print(\"Creating summary statistics...\")\n",
    "\n",
    "pit_info_list = []\n",
    "\n",
    "for i, pit in enumerate(all_pits):\n",
    "    # layer info\n",
    "    num_primary_grain_form = sum(1 for layer in pit.snow_profile.layers \n",
    "                                if layer.grain_form_primary is not None)\n",
    "    num_primary_grain_size = sum(1 for layer in pit.snow_profile.layers \n",
    "                                if (layer.grain_form_primary is not None and \n",
    "                                    layer.grain_form_primary.grain_size_avg is not None))\n",
    "    num_hand_hardness = sum(1 for layer in pit.snow_profile.layers \n",
    "                                if (layer.hardness is not None))\n",
    "\n",
    "    pit_info_dict = {\n",
    "        # Metadata\n",
    "        \"PitID\": pit.core_info.pit_id,\n",
    "        \"Date\": pit.core_info.date,\n",
    "        # User\n",
    "        \"SnowPilot Username\": pit.core_info.user.username,\n",
    "        \"Professional\": pit.core_info.user.professional,\n",
    "        \"Operation Name\": pit.core_info.user.operation_name,\n",
    "        # Location\n",
    "        \"Latitude\": pit.core_info.location.latitude,\n",
    "        \"Longitude\": pit.core_info.location.longitude,\n",
    "        \"Elevation\": pit.core_info.location.elevation,\n",
    "        \"Aspect\": pit.core_info.location.aspect,\n",
    "        \"Slope Angle\": pit.core_info.location.slope_angle,\n",
    "        \"Country\": pit.core_info.location.country,\n",
    "        \"Region\": pit.core_info.location.region,\n",
    "        \"Pit Near Avalanche\": pit.core_info.location.pit_near_avalanche,\n",
    "        \"Pit Near Avalanche Location\": pit.core_info.location.pit_near_avalanche_location,\n",
    "        # Snow Profile\n",
    "        \"HS\": pit.snow_profile.hs,\n",
    "        # Layers\n",
    "        \"Num Layers\": len(pit.snow_profile.layers),\n",
    "        \"num Layers wPrimary Grain Form\": num_primary_grain_form,\n",
    "        \"num Layers wPrimary Grain Size\": num_primary_grain_size,\n",
    "        \"num Layers wHand Hardness\": num_hand_hardness,\n",
    "        # Stability Tests\n",
    "        \"Num ECT\": len(pit.stability_tests.ECT),\n",
    "        \"Num CT\": len(pit.stability_tests.CT),\n",
    "        \"Num RBlock\": len(pit.stability_tests.RBlock),\n",
    "        \"Num PST\": len(pit.stability_tests.PST),\n",
    "    }\n",
    "    pit_info_list.append(pit_info_dict)\n",
    "\n",
    "# Create DataFrame only once after collecting all data\n",
    "print(\"Creating DataFrame...\")\n",
    "pit_info_df = pd.DataFrame(pit_info_list)\n",
    "\n",
    "print(f\"✅ Successfully created DataFrame with {len(pit_info_df)} rows and {len(pit_info_df.columns)} columns\")\n",
    "print(f\"DataFrame shape: {pit_info_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4eb635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary Statistics of Full Dataset ===\n",
      "\n",
      "Total number of pits: 50278\n",
      "Date range: Unable to determine (mixed data types)\n",
      "\n",
      "=== LAYER INFORMATION ===\n",
      "Pits with primary grain form data: 47238 (94.0%)\n",
      "Pits with primary grain size data: 35541 (70.7%)\n",
      "Pits with hand hardness data: 49701 (98.9%)\n",
      "\n",
      "Total number of layers across all pits: 371429\n",
      "Total number of layers with primary grain form data: 305811 (82.3%)\n",
      "Total number of layers with primary grain size data: 176044 (47.4%)\n",
      "Total number of layers with hand hardness data: 336888 (90.7%)\n",
      "\n",
      "=== STABILITY TESTS ===\n",
      "Pits with ECT tests: 34327 (68.3%)\n",
      "Pits with CT tests: 28959 (57.6%)\n",
      "Pits with RBlock tests: 215 (0.4%)\n",
      "Pits with PST tests: 5154 (10.3%)\n",
      "\n",
      "Total ECT tests: 47684\n",
      "Total CT tests: 51599\n",
      "Total RBlock tests: 241\n",
      "Total PST tests: 6213\n",
      "\n",
      "Total number of stability test results: 105737\n",
      "\n",
      "=== USER INFORMATION ===\n",
      "Unique users: 5380\n",
      "Professional users: 32707 (65.1%)\n",
      "Unique operations: 561\n",
      "\n",
      "=== PITS NEAR AVALANCHE ===\n",
      "Total Pits near avalanche: 1568\n",
      "\n",
      "Pit Near Avalanche Location\n",
      "crown    795\n",
      "flank    399\n",
      "other    231\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "=== DATA COMPLETENESS ===\n",
      "                             Missing Count  Missing %\n",
      "Pit Near Avalanche Location          48853       97.2\n",
      "Pit Near Avalanche                   48710       96.9\n",
      "Operation Name                       17771       35.3\n",
      "Latitude                             14184       28.2\n",
      "Longitude                            14184       28.2\n",
      "Slope Angle                           4763        9.5\n",
      "Aspect                                4191        8.3\n",
      "HS                                    1970        3.9\n",
      "Region                                1347        2.7\n",
      "Elevation                             1340        2.7\n",
      "Country                                 64        0.1\n",
      "Date                                    21        0.0\n",
      "SnowPilot Username                      17        0.0\n"
     ]
    }
   ],
   "source": [
    "# Display Summary Stats\n",
    "\n",
    "# Summary statistics for pit_info_df \n",
    "print(\"=== Summary Statistics of Full Dataset ===\\n\")\n",
    "\n",
    "# Helper function to extract numeric values from [value, unit] lists\n",
    "def extract_numeric_value(data_series):\n",
    "    \"\"\"Extract numeric values from lists of format [value, unit]\"\"\"\n",
    "    numeric_values = []\n",
    "    for item in data_series:\n",
    "        if item is not None and isinstance(item, list) and len(item) >= 1:\n",
    "            try:\n",
    "                numeric_values.append(float(item[0]))\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "        elif item is not None:\n",
    "            try:\n",
    "                numeric_values.append(float(item))\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    return pd.Series(numeric_values)\n",
    "\n",
    "# Basic dataset info\n",
    "print(f\"Total number of pits: {len(pit_info_df)}\")\n",
    "\n",
    "# Handle dates safely\n",
    "try:\n",
    "    date_min = pit_info_df['Date'].min()\n",
    "    date_max = pit_info_df['Date'].max()\n",
    "    print(f\"Date range: {date_min} to {date_max}\")\n",
    "except:\n",
    "    print(\"Date range: Unable to determine (mixed data types)\")\n",
    "print()\n",
    "\n",
    "# Layer information\n",
    "print(\"=== LAYER INFORMATION ===\")\n",
    "try:\n",
    "    layers_numeric = pd.to_numeric(pit_info_df['Num Layers'], errors='coerce')\n",
    "    layers_clean = layers_numeric.dropna()\n",
    "\n",
    "    \n",
    "    # Grain form and size data\n",
    "    grain_form_numeric = pd.to_numeric(pit_info_df['num Layers wPrimary Grain Form'], errors='coerce')\n",
    "    grain_size_numeric = pd.to_numeric(pit_info_df['num Layers wPrimary Grain Size'], errors='coerce')\n",
    "    hardness_numeric = pd.to_numeric(pit_info_df['num Layers wHand Hardness'], errors='coerce')\n",
    "\n",
    "    pits_with_grain_form = (grain_form_numeric > 0).sum()\n",
    "    pits_with_grain_size = (grain_size_numeric > 0).sum()\n",
    "    pits_with_hardness = (hardness_numeric > 0).sum()\n",
    "\n",
    "    print(f\"Pits with primary grain form data: {pits_with_grain_form} ({pits_with_grain_form/len(pit_info_df)*100:.1f}%)\")\n",
    "    print(f\"Pits with primary grain size data: {pits_with_grain_size} ({pits_with_grain_size/len(pit_info_df)*100:.1f}%)\")\n",
    "    print(f\"Pits with hand hardness data: {pits_with_hardness} ({pits_with_hardness/len(pit_info_df)*100:.1f}%)\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Total Layers\n",
    "    total_layers = layers_clean.sum()\n",
    "    layers_with_grain_form = grain_form_numeric.sum()\n",
    "    layers_with_grain_size = grain_size_numeric.sum()\n",
    "    layers_with_hardness = hardness_numeric.sum()\n",
    "\n",
    "    print(f\"Total number of layers across all pits: {total_layers}\")\n",
    "    print(f\"Total number of layers with primary grain form data: {layers_with_grain_form} ({layers_with_grain_form/total_layers*100:.1f}%)\")\n",
    "    print(f\"Total number of layers with primary grain size data: {layers_with_grain_size} ({layers_with_grain_size/total_layers*100:.1f}%)\")\n",
    "    print(f\"Total number of layers with hand hardness data: {layers_with_hardness} ({layers_with_hardness/total_layers*100:.1f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Layer data: Unable to process ({str(e)})\")\n",
    "print()\n",
    "\n",
    "# Stability tests\n",
    "print(\"=== STABILITY TESTS ===\")\n",
    "try:\n",
    "    ect_numeric = pd.to_numeric(pit_info_df['Num ECT'], errors='coerce')\n",
    "    ct_numeric = pd.to_numeric(pit_info_df['Num CT'], errors='coerce')\n",
    "    rblock_numeric = pd.to_numeric(pit_info_df['Num RBlock'], errors='coerce')\n",
    "    pst_numeric = pd.to_numeric(pit_info_df['Num PST'], errors='coerce')\n",
    "    \n",
    "    pits_with_ect = (ect_numeric > 0).sum()\n",
    "    pits_with_ct = (ct_numeric > 0).sum()\n",
    "    pits_with_rblock = (rblock_numeric > 0).sum()\n",
    "    pits_with_pst = (pst_numeric > 0).sum()\n",
    "    \n",
    "    print(f\"Pits with ECT tests: {pits_with_ect} ({pits_with_ect/len(pit_info_df)*100:.1f}%)\")\n",
    "    print(f\"Pits with CT tests: {pits_with_ct} ({pits_with_ct/len(pit_info_df)*100:.1f}%)\")\n",
    "    print(f\"Pits with RBlock tests: {pits_with_rblock} ({pits_with_rblock/len(pit_info_df)*100:.1f}%)\")\n",
    "    print(f\"Pits with PST tests: {pits_with_pst} ({pits_with_pst/len(pit_info_df)*100:.1f}%)\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    total_ect = ect_numeric.sum()\n",
    "    total_ct = ct_numeric.sum()\n",
    "    total_rblock = rblock_numeric.sum()\n",
    "    total_pst = pst_numeric.sum()\n",
    "\n",
    "    print(f\"Total ECT tests: {total_ect}\")\n",
    "    print(f\"Total CT tests: {total_ct}\")\n",
    "    print(f\"Total RBlock tests: {total_rblock}\")\n",
    "    print(f\"Total PST tests: {total_pst}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(f\"Total number of stability test results: {total_ect + total_ct + total_rblock + total_pst}\")\n",
    "except Exception as e:\n",
    "    print(f\"Stability test data: Unable to process ({str(e)})\")\n",
    "print()\n",
    "\n",
    "# User information\n",
    "print(\"=== USER INFORMATION ===\")\n",
    "try:\n",
    "    print(f\"Unique users: {pit_info_df['SnowPilot Username'].nunique()}\")\n",
    "    \n",
    "    # Handle professional status\n",
    "    professional_data = pit_info_df['Professional']\n",
    "    professional_count = professional_data.sum()\n",
    "    print(f\"Professional users: {professional_count} ({professional_count/len(pit_info_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"Unique operations: {pit_info_df['Operation Name'].nunique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"User data: Unable to process ({str(e)})\")\n",
    "print()\n",
    "\n",
    "# Pit near avalanche location breakdown\n",
    "print(\"=== PITS NEAR AVALANCHE ===\")\n",
    "try:\n",
    "    pits_near_avalanche = pit_info_df['Pit Near Avalanche'].sum()\n",
    "    print(f\"Total Pits near avalanche: {pits_near_avalanche}\")\n",
    "    print()\n",
    "    location_counts = pit_info_df['Pit Near Avalanche Location'].value_counts()\n",
    "    print(location_counts)\n",
    "    print()\n",
    "\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Avalanche location data: Unable to process ({str(e)})\")\n",
    "print()\n",
    "\n",
    "# Data completeness\n",
    "print(\"=== DATA COMPLETENESS ===\")\n",
    "try:\n",
    "    missing_data = pit_info_df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(pit_info_df)) * 100\n",
    "    completeness_df = pd.DataFrame({\n",
    "        'Missing Count': missing_data,\n",
    "        'Missing %': missing_percent.round(1)\n",
    "    }).sort_values('Missing %', ascending=False)\n",
    "    \n",
    "    # Only show columns with missing data\n",
    "    incomplete_data = completeness_df[completeness_df['Missing Count'] > 0]\n",
    "    if len(incomplete_data) > 0:\n",
    "        print(incomplete_data)\n",
    "    else:\n",
    "        print(\"No missing data found!\")\n",
    "except Exception as e:\n",
    "    print(f\"Data completeness analysis: Unable to process ({str(e)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpylot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
