{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e12383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snowpylot import caaml_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e11ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pits(folder_path):\n",
    "    \"\"\"\n",
    "    Function to parse CAAML files in the specified folder with error handling\n",
    "    \"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    files = [\n",
    "        f for f in os.listdir(folder_path) if f.endswith(\".xml\")\n",
    "    ]  # List of all .xml files in the folder\n",
    "\n",
    "    pits_list = []\n",
    "    failed_files = []\n",
    "    \n",
    "    print(f\"Found {len(files)} XML files to process...\")\n",
    "\n",
    "    for i, file in enumerate(files):  # iterate through each file in the folder\n",
    "        try:\n",
    "            file_path = folder_path + \"/\" + file  # create the file path\n",
    "            \n",
    "            # First, do a quick XML validation check\n",
    "            ET.parse(file_path).getroot()\n",
    "            \n",
    "            # If XML is valid, parse with caaml_parser\n",
    "            pit = caaml_parser(file_path)  # parse the file\n",
    "            pits_list.append(pit)\n",
    "                \n",
    "        except ET.ParseError as e:\n",
    "            failed_files.append((file, f\"XML ParseError: {e}\"))\n",
    "            print(f\"⚠️ Skipping {file}: XML ParseError - {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_files.append((file, f\"Other error: {e}\"))\n",
    "            print(f\"⚠️ Skipping {file}: {type(e).__name__} - {e}\")\n",
    "    \n",
    "    print(f\"✅ Successfully parsed {len(pits_list)} files\")\n",
    "    print(f\"⚠️ Failed to parse {len(failed_files)} files\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(\"Failed files:\")\n",
    "        for file, error in failed_files[:10]:  # Show first 10 failed files\n",
    "            print(f\"  - {file}: {error}\")\n",
    "        if len(failed_files) > 10:\n",
    "            print(f\"  ... and {len(failed_files) - 10} more\")\n",
    "\n",
    "    return pits_list, failed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2f6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50279 XML files to process...\n",
      "Processed 1000/50279 files...\n",
      "Processed 2000/50279 files...\n",
      "Processed 3000/50279 files...\n",
      "Processed 4000/50279 files...\n",
      "Processed 5000/50279 files...\n",
      "Processed 6000/50279 files...\n",
      "Processed 7000/50279 files...\n",
      "Processed 8000/50279 files...\n",
      "Processed 9000/50279 files...\n",
      "Processed 10000/50279 files...\n",
      "Processed 11000/50279 files...\n",
      "Processed 12000/50279 files...\n",
      "Processed 13000/50279 files...\n",
      "Processed 14000/50279 files...\n",
      "Processed 15000/50279 files...\n",
      "Processed 16000/50279 files...\n",
      "Processed 17000/50279 files...\n",
      "Processed 18000/50279 files...\n",
      "Processed 19000/50279 files...\n",
      "Processed 20000/50279 files...\n",
      "Processed 21000/50279 files...\n",
      "Processed 22000/50279 files...\n",
      "Processed 23000/50279 files...\n",
      "Processed 24000/50279 files...\n",
      "Processed 25000/50279 files...\n",
      "Processed 26000/50279 files...\n",
      "Processed 27000/50279 files...\n",
      "Processed 28000/50279 files...\n",
      "Processed 29000/50279 files...\n",
      "Processed 30000/50279 files...\n",
      "Processed 31000/50279 files...\n",
      "Processed 32000/50279 files...\n",
      "Processed 33000/50279 files...\n",
      "Processed 34000/50279 files...\n",
      "Processed 35000/50279 files...\n",
      "Processed 36000/50279 files...\n",
      "Processed 37000/50279 files...\n",
      "Processed 38000/50279 files...\n",
      "Processed 39000/50279 files...\n",
      "Processed 40000/50279 files...\n",
      "Processed 41000/50279 files...\n",
      "Processed 42000/50279 files...\n",
      "⚠️ Skipping snowpits-55240-caaml.xml: XML ParseError - no element found: line 2, column 0\n",
      "Processed 43000/50279 files...\n",
      "Processed 44000/50279 files...\n",
      "Processed 45000/50279 files...\n",
      "Processed 46000/50279 files...\n",
      "Processed 47000/50279 files...\n",
      "Processed 48000/50279 files...\n",
      "Processed 49000/50279 files...\n",
      "Processed 50000/50279 files...\n",
      "✅ Successfully parsed 50278 files\n",
      "⚠️ Failed to parse 1 files\n",
      "Failed files:\n",
      "  - snowpits-55240-caaml.xml: XML ParseError: no element found: line 2, column 0\n",
      "\n",
      "Dataset summary:\n",
      "Total successfully parsed pits: 50278\n",
      "Total failed files: 1\n"
     ]
    }
   ],
   "source": [
    "# Parse all pits with error handling\n",
    "all_pits, failed_files = parse_pits(\"../snowpits/combined_caaml_files/\")\n",
    "\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"Total successfully parsed pits: {len(all_pits)}\")\n",
    "print(f\"Total failed files: {len(failed_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e3305",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     16\u001b[39m pit_info_dict = {\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Metadata\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPitID\u001b[39m\u001b[33m\"\u001b[39m: pit.core_info.pit_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNum PST\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(pit.stability_tests.PST),\n\u001b[32m     45\u001b[39m }\n\u001b[32m     46\u001b[39m pit_info_list.append(pit_info_dict)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m pit_info_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpit_info_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/frame.py:851\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m         arrays,\n\u001b[32m    861\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         typ=manager,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/internals/construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/internals/construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/internals/construction.py:945\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     contents = \u001b[43mconvert_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/internals/construction.py:1071\u001b[39m, in \u001b[36mconvert_object_array\u001b[39m\u001b[34m(content, dtype, dtype_backend, coerce_float)\u001b[39m\n\u001b[32m   1067\u001b[39m             arr = maybe_cast_to_datetime(arr, dtype)\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m arrays = [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/snowpylot-applications/snowpylot-env/lib/python3.13/site-packages/pandas/core/internals/construction.py:1030\u001b[39m, in \u001b[36mconvert_object_array.<locals>.convert\u001b[39m\u001b[34m(arr)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(arr):\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype != np.dtype(\u001b[33m\"\u001b[39m\u001b[33mO\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m         arr = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m            \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtry_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnumpy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m         \u001b[38;5;66;03m# Notes on cases that get here 2023-02-15\u001b[39;00m\n\u001b[32m   1036\u001b[39m         \u001b[38;5;66;03m# 1) we DO get here when arr is all Timestamps and dtype=None\u001b[39;00m\n\u001b[32m   1037\u001b[39m         \u001b[38;5;66;03m# 2) disabling this doesn't break the world, so this must be\u001b[39;00m\n\u001b[32m   1038\u001b[39m         \u001b[38;5;66;03m#    getting caught at a higher level\u001b[39;00m\n\u001b[32m   1039\u001b[39m         \u001b[38;5;66;03m# 3) passing convert_non_numeric to maybe_convert_objects get this right\u001b[39;00m\n\u001b[32m   1040\u001b[39m         \u001b[38;5;66;03m# 4) convert_non_numeric?\u001b[39;00m\n\u001b[32m   1042\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Summary Stats\n",
    "\n",
    "pit_info_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    num_primary_grain_form = 0  # initialize\n",
    "    num_primary_grain_size = 0  # initialize\n",
    "    for layer in pit.snow_profile.layers:  # iterate through each layer in the pit\n",
    "        if layer.grain_form_primary is not None:  # if the layer has a primary grain form\n",
    "            num_primary_grain_form += 1  # increment the number of primary grain forms\n",
    "            if (\n",
    "                layer.grain_form_primary.grain_size_avg is not None\n",
    "            ):  # if the layer has a primary grain size\n",
    "                num_primary_grain_size += 1  # increment the number of primary grain sizes\n",
    "\n",
    "    pit_info_dict = {\n",
    "        # Metadata\n",
    "        \"PitID\": pit.core_info.pit_id,\n",
    "        \"Date\": pit.core_info.date,\n",
    "        # User\n",
    "        \"SnowPilot Username\": pit.core_info.user.username,\n",
    "        \"Professional\": pit.core_info.user.professional,\n",
    "        \"Operation Name\": pit.core_info.user.operation_name,\n",
    "        # Location\n",
    "        \"Latitude\": pit.core_info.location.latitude,\n",
    "        \"Longitude\": pit.core_info.location.longitude,\n",
    "        \"Elevation\": pit.core_info.location.elevation,\n",
    "        \"Aspect\": pit.core_info.location.aspect,\n",
    "        \"Slope Angle\": pit.core_info.location.slope_angle,\n",
    "        \"Country\": pit.core_info.location.country,\n",
    "        \"Region\": pit.core_info.location.region,\n",
    "        \"Pit Near Avalanche\": pit.core_info.location.pit_near_avalanche,\n",
    "        \"Pit Near Avalanche Location\": pit.core_info.location.pit_near_avalanche_location,\n",
    "        # Snow Profile\n",
    "        \"HS\": pit.snow_profile.hs,\n",
    "        # Layers\n",
    "        \"Num Layers\": len(pit.snow_profile.layers),\n",
    "        \"num Layers wPrimary Grain Form\": num_primary_grain_form,\n",
    "        \"num Layers wPrimary Grain Size\": num_primary_grain_size,\n",
    "        # Stability Tests\n",
    "        \"Num ECT\": len(pit.stability_tests.ECT),\n",
    "        \"Num CT\": len(pit.stability_tests.CT),\n",
    "        \"Num RBlock\": len(pit.stability_tests.RBlock),\n",
    "        \"Num PST\": len(pit.stability_tests.PST),\n",
    "    }\n",
    "    pit_info_list.append(pit_info_dict)\n",
    "\n",
    "    pit_info_df = pd.DataFrame(pit_info_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpylot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
