{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a245649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from snowpylot import caaml_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55af42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pits(folder_path):\n",
    "    \"\"\"\n",
    "    Function to parse CAAML files in the specified folder\n",
    "    \"\"\"\n",
    "    files = [\n",
    "        f for f in os.listdir(folder_path) if f.endswith(\".xml\")\n",
    "    ]  # List of all .xml files in the folder\n",
    "\n",
    "    pits_list = []\n",
    "\n",
    "    for file in files:  # iterate through each file in the folder\n",
    "        file_path = os.path.join(folder_path, file)  # create the file path\n",
    "        try:\n",
    "            pit = caaml_parser(file_path)  # parse the file\n",
    "            pits_list.append(pit)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file}: {str(e)}\")\n",
    "\n",
    "    return pits_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c8c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 extracted directories to process:\n",
      "  📁 sverplanck-snowpits-25-07-21-07-03\n",
      "  📁 sverplanck-snowpits-25-07-21-07-04\n",
      "  📁 sverplanck-snowpits-25-07-21-07-05\n",
      "  📁 sverplanck-snowpits-25-07-21-07-06\n",
      "  📁 sverplanck-snowpits-25-07-21-07-07\n",
      "  📁 sverplanck-snowpits-25-07-21-07-10\n",
      "  📁 sverplanck-snowpits-25-07-21-07-11\n",
      "  📁 sverplanck-snowpits-25-07-21-07-12\n",
      "  📁 sverplanck-snowpits-25-07-21-07-13\n",
      "  📁 sverplanck-snowpits-25-07-21-07-14\n",
      "  📁 sverplanck-snowpits-25-07-21-07-15\n",
      "  📁 sverplanck-snowpits-25-07-21-07-16\n",
      "  📁 sverplanck-snowpits-25-07-21-07-17\n",
      "  📁 sverplanck-snowpits-25-07-21-07-18\n",
      "  📁 sverplanck-snowpits-25-07-21-07-19\n",
      "  📁 sverplanck-snowpits-25-07-21-07-20\n",
      "  📁 sverplanck-snowpits-25-07-21-07-21\n",
      "  📁 sverplanck-snowpits-25-07-21-07-22\n",
      "  📁 sverplanck-snowpits-25-07-21-07-23\n",
      "  📁 sverplanck-snowpits-25-07-21-07-24\n",
      "  📁 sverplanck-snowpits-25-07-21-07-25\n",
      "  📁 sverplanck-snowpits-25-07-21-07-26\n",
      "  📁 sverplanck-snowpits-25-07-21-07-27\n",
      "  📁 sverplanck-snowpits-25-07-21-07-28\n",
      "  📁 sverplanck-snowpits-25-07-21-07-29\n",
      "  📁 sverplanck-snowpits-25-07-21-07-30\n",
      "  📁 sverplanck-snowpits-25-07-21-07-31\n",
      "  📁 sverplanck-snowpits-25-07-21-07-32\n",
      "  📁 sverplanck-snowpits-25-07-21-07-33\n",
      "  📁 sverplanck-snowpits-25-07-21-07-34\n",
      "  📁 sverplanck-snowpits-25-07-21-07-35\n",
      "  📁 sverplanck-snowpits-25-07-21-07-36\n",
      "  📁 sverplanck-snowpits-25-07-21-07-38\n",
      "  📁 sverplanck-snowpits-25-07-21-07-39\n",
      "  📁 sverplanck-snowpits-25-07-21-07-40\n",
      "  📁 sverplanck-snowpits-25-07-21-07-41\n",
      "  📁 sverplanck-snowpits-25-07-21-07-42\n",
      "  📁 sverplanck-snowpits-25-07-21-07-43\n",
      "  📁 sverplanck-snowpits-25-07-21-07-44\n",
      "  📁 sverplanck-snowpits-25-07-21-07-45\n",
      "  📁 sverplanck-snowpits-25-07-21-07-47\n",
      "  📁 sverplanck-snowpits-25-07-21-07-48\n",
      "  📁 sverplanck-snowpits-25-07-21-07-49\n",
      "  📁 sverplanck-snowpits-25-07-21-07-50\n",
      "  📁 sverplanck-snowpits-25-07-21-07-51\n",
      "\n",
      "Parsing snowpit files from each directory...\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-16\n",
      "  ✅ Parsed 1291 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-29\n",
      "  ✅ Parsed 975 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-11\n",
      "  ✅ Parsed 113 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-27\n",
      "  ✅ Parsed 2600 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-18\n",
      "  ✅ Parsed 696 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-20\n",
      "  ✅ Parsed 98 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-45\n",
      "  ✅ Parsed 975 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-42\n",
      "  ✅ Parsed 531 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-21\n",
      "  ✅ Parsed 141 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-26\n",
      "  ✅ Parsed 87 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-19\n",
      "  ✅ Parsed 537 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-10\n",
      "  ✅ Parsed 1285 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-17\n",
      "  ✅ Parsed 2151 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-28\n",
      "  ✅ Parsed 426 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-43\n",
      "  ✅ Parsed 76 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-44\n",
      "Error parsing snowpits-55240-caaml.xml: no element found: line 2, column 0\n",
      "  ✅ Parsed 247 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-50\n",
      "  ✅ Parsed 1367 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-35\n",
      "  ✅ Parsed 189 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-32\n",
      "  ✅ Parsed 625 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-04\n",
      "  ✅ Parsed 543 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-03\n",
      "  ✅ Parsed 321 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-51\n",
      "  ✅ Parsed 653 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-05\n",
      "  ✅ Parsed 407 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-33\n",
      "  ✅ Parsed 1248 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-34\n",
      "  ✅ Parsed 418 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-48\n",
      "  ✅ Parsed 1208 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-41\n",
      "  ✅ Parsed 647 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-12\n",
      "  ✅ Parsed 1381 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-15\n",
      "  ✅ Parsed 296 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-23\n",
      "  ✅ Parsed 314 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-24\n",
      "  ✅ Parsed 377 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-47\n",
      "  ✅ Parsed 1630 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-40\n",
      "  ✅ Parsed 656 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-49\n",
      "  ✅ Parsed 1684 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-25\n",
      "  ✅ Parsed 108 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-22\n",
      "  ✅ Parsed 679 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-14\n",
      "  ✅ Parsed 127 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-13\n",
      "  ✅ Parsed 649 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-31\n",
      "  ✅ Parsed 313 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-36\n",
      "  ✅ Parsed 1023 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-38\n",
      "  ✅ Parsed 1627 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-07\n",
      "  ✅ Parsed 156 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-39\n",
      "  ✅ Parsed 1388 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-06\n",
      "  ✅ Parsed 57 snowpits\n",
      "\n",
      "Processing: sverplanck-snowpits-25-07-21-07-30\n",
      "  ✅ Parsed 1690 snowpits\n",
      "\n",
      "🎉 Parsing complete!\n",
      "Total directories processed: 45\n",
      "Total snowpits parsed: 34010\n",
      "Length of all_pits list: 34010\n",
      "\n",
      "Sample pit information:\n",
      "  First pit ID: 27704\n",
      "  Date: 2020-12-30\n",
      "  Number of layers: 6\n",
      "  Unique pit IDs: 32649\n"
     ]
    }
   ],
   "source": [
    "# Find all directories in new_data (these are the extracted folders)\n",
    "new_data_dir = \"../snowpits/new_data\"\n",
    "all_pits = []\n",
    "\n",
    "# Get all items in new_data directory\n",
    "items_in_new_data = os.listdir(new_data_dir)\n",
    "\n",
    "# Filter to only directories (ignore tar.gz files)\n",
    "extracted_directories = [\n",
    "    item for item in items_in_new_data \n",
    "    if os.path.isdir(os.path.join(new_data_dir, item)) and not item.startswith('.')\n",
    "]\n",
    "\n",
    "print(f\"Found {len(extracted_directories)} extracted directories to process:\")\n",
    "for directory in sorted(extracted_directories):\n",
    "    print(f\"  📁 {directory}\")\n",
    "\n",
    "print(\"\\nParsing snowpit files from each directory...\")\n",
    "\n",
    "# Parse pits from each extracted directory\n",
    "total_pits_parsed = 0\n",
    "for directory in extracted_directories:\n",
    "    directory_path = os.path.join(new_data_dir, directory)\n",
    "    print(f\"\\nProcessing: {directory}\")\n",
    "    \n",
    "    try:\n",
    "        # Parse all pits in this directory\n",
    "        pits_from_directory = parse_pits(directory_path)\n",
    "        directory_pit_count = len(pits_from_directory)\n",
    "        \n",
    "        # Add to the master list\n",
    "        all_pits.extend(pits_from_directory)\n",
    "        total_pits_parsed += directory_pit_count\n",
    "        \n",
    "        print(f\"  ✅ Parsed {directory_pit_count} snowpits\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error processing directory {directory}: {str(e)}\")\n",
    "\n",
    "print(\"\\n🎉 Parsing complete!\")\n",
    "print(f\"Total directories processed: {len(extracted_directories)}\")\n",
    "print(f\"Total snowpits parsed: {total_pits_parsed}\")\n",
    "print(f\"Length of all_pits list: {len(all_pits)}\")\n",
    "\n",
    "# Display some basic info about the parsed data\n",
    "if all_pits:\n",
    "    print(\"\\nSample pit information:\")\n",
    "    sample_pit = all_pits[0]\n",
    "    print(f\"  First pit ID: {sample_pit.core_info.pit_id}\")\n",
    "    print(f\"  Date: {sample_pit.core_info.date}\")\n",
    "    print(f\"  Number of layers: {len(sample_pit.snow_profile.layers)}\")\n",
    "    \n",
    "    # Show distribution of pits by some basic metadata if available\n",
    "    pit_ids = [pit.core_info.pit_id for pit in all_pits if pit.core_info.pit_id]\n",
    "    print(f\"  Unique pit IDs: {len(set(pit_ids))}\")\n",
    "else:\n",
    "    print(\"⚠️  No pits were successfully parsed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c62f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Summary\n",
    "\n",
    "pit_info = []\n",
    "layer_info = []\n",
    "density_info = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    pit_dict = {\n",
    "        'pit_id': pit.core_info.pit_id,\n",
    "        'layer_count': len(pit.snow_profile.layers),\n",
    "        'density_count': len(pit.snow_profile.density_profile)\n",
    "    }\n",
    "    pit_info.append(pit_dict)\n",
    "\n",
    "    for density in pit.snow_profile.density_profile:\n",
    "        density_dict = {\n",
    "            'pit_id': pit.core_info.pit_id,\n",
    "            'depth_top': density.depth_top,\n",
    "            'thickness': density.thickness,\n",
    "            'density': density.density,\n",
    "        }\n",
    "        density_info.append(density_dict)\n",
    "\n",
    "    for layer in pit.snow_profile.layers:\n",
    "        layer_dict = {\n",
    "            'pit_id': pit.core_info.pit_id,\n",
    "            'depth_top': layer.depth_top,\n",
    "            'thickness': layer.thickness,\n",
    "            'hardness': layer.hardness,\n",
    "            'wetness': layer.wetness,\n",
    "            'layer_of_concern': layer.layer_of_concern,\n",
    "            'grain_form_primary': layer.grain_form_primary,\n",
    "            'grain_form_secondary': layer.grain_form_secondary,\n",
    "        }\n",
    "        layer_info.append(layer_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91ca34b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pits: 34,010\n",
      "Pits with density measurements: 2,007\n",
      "Percentage of pits with density data: 5.9%\n"
     ]
    }
   ],
   "source": [
    "# Summary stats for pit_info\n",
    "pit_info_df = pd.DataFrame(pit_info)\n",
    "total_pits = len(pit_info_df)\n",
    "print(f\"Total pits: {total_pits:,}\")\n",
    "\n",
    "# Calculate number of pits with density measurements\n",
    "pits_with_density = (pit_info_df['density_count'] > 0).sum()\n",
    "percentage_with_density = (pits_with_density / total_pits) * 100\n",
    "\n",
    "print(f\"Pits with density measurements: {pits_with_density:,}\")\n",
    "print(f\"Percentage of pits with density data: {percentage_with_density:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ce7faba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density_info_df\n",
      "Number of values for depth_top                :   14,538\n",
      "Number of values for thickness                :    7,021\n",
      "Number of values for density                  :   14,538\n"
     ]
    }
   ],
   "source": [
    "# Summary stats for density_info\n",
    "density_info_df = pd.DataFrame(density_info)\n",
    "print(\"density_info_df\")\n",
    "for column in density_info_df.columns:\n",
    "        # Count non-null values\n",
    "        non_null_count = density_info_df[column].notna().sum()\n",
    "        print(f\"Number of values for {column:25}: {non_null_count:8,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b391c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_info_df\n",
      "Number of values for depth_top                :  254,387\n",
      "Number of values for thickness                :  254,387\n",
      "Number of values for hardness                 :  230,434\n",
      "Number of values for wetness                  :   60,228\n",
      "Number of values for layer_of_concern         :   24,628\n",
      "Number of values for grain_form_primary       :  208,388\n",
      "Number of values for grain_form_secondary     :   28,436\n"
     ]
    }
   ],
   "source": [
    "# Summary stats for layer_info\n",
    "layer_info_df = pd.DataFrame(layer_info)\n",
    "print(\"layer_info_df\")\n",
    "for column in layer_info_df.columns:\n",
    "        # Count non-null values\n",
    "        non_null_count = layer_info_df[column].notna().sum()\n",
    "        print(f\"Number of values for {column:25}: {non_null_count:8,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpylot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
